<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*       on 2021-05-24T17:10:36-05:00       *-->
<!--*   A recent stable commit (2020-08-09):   *-->
<!--* 98f21740783f166a773df4dc83cab5293ab63a4a *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Inner products, norms, angles</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [['\\(','\\)']]
    },
    asciimath2jax: {
        ignoreClass: ".*",
        processClass: "has_am"
    },
    jax: ["input/AsciiMath"],
    extensions: ["asciimath2jax.js"],
    TeX: {
        extensions: ["extpfeil.js", "autobold.js", "https://pretextbook.org/js/lib/mathjaxknowl.js", "AMScd.js", ],
        // scrolling to fragment identifiers is controlled by other Javascript
        positionToHash: false,
        equationNumbers: { autoNumber: "none", useLabelIds: true, },
        TagSide: "right",
        TagIndent: ".8em",
    },
    // HTML-CSS output Jax to be dropped for MathJax 3.0
    "HTML-CSS": {
        scale: 88,
        mtextFontInherit: true,
    },
    CommonHTML: {
        scale: 88,
        mtextFontInherit: true,
    },
});
</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_CHTML-full"></script><script xmlns:svg="http://www.w3.org/2000/svg" src="https://pretextbook.org/js/lib/jquery.min.js"></script><script xmlns:svg="http://www.w3.org/2000/svg" src="https://pretextbook.org/js/lib/jquery.sticky.js"></script><script xmlns:svg="http://www.w3.org/2000/svg" src="https://pretextbook.org/js/lib/jquery.espy.min.js"></script><script xmlns:svg="http://www.w3.org/2000/svg" src="https://pretextbook.org/js/0.13/pretext.js"></script><script xmlns:svg="http://www.w3.org/2000/svg" src="https://pretextbook.org/js/0.13/pretext_add_on.js"></script><script xmlns:svg="http://www.w3.org/2000/svg" src="https://pretextbook.org/js/lib/knowl.js"></script><!--knowl.js code controls Sage Cells within knowls--><script xmlns:svg="http://www.w3.org/2000/svg">sagecellEvalName='Evaluate (Sage)';
</script><link xmlns:svg="http://www.w3.org/2000/svg" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://fonts.googleapis.com/css?family=Inconsolata:400,700&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://pretextbook.org/css/0.31/pretext.css" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://pretextbook.org/css/0.31/pretext_add_on.css" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://pretextbook.org/css/0.31/banner_default.css" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://pretextbook.org/css/0.31/toc_default.css" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://pretextbook.org/css/0.31/knowls_default.css" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://pretextbook.org/css/0.31/style_default.css" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://pretextbook.org/css/0.31/colors_default.css" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://pretextbook.org/css/0.31/setcolors.css" rel="stylesheet" type="text/css">
<!-- 2019-10-12: Temporary - CSS file for experiments with styling --><link xmlns:svg="http://www.w3.org/2000/svg" href="developer.css" rel="stylesheet" type="text/css">
</head>
<body class="mathbook-book has-toc has-sidebar-left">
<a class="assistive" href="#content">Skip to main content</a><div xmlns:svg="http://www.w3.org/2000/svg" id="latex-macros" class="hidden-content" style="display:none">\(\newcommand{\Z}{{\mathbb Z}}
\newcommand{\Q}{{\mathbb Q}}
\newcommand{\R}{{\mathbb R}}
\newcommand{\C}{{\mathbb C}}
\newcommand{\T}{{\mathbb T}}
\newcommand{\F}{{\mathbb F}}
\newcommand{\HH}{{\mathbb H}}
\newcommand{\compose}{\circ}
\newcommand{\bolda}{{\mathbf a}}
\newcommand{\boldb}{{\mathbf b}}
\newcommand{\boldc}{{\mathbf c}}
\newcommand{\boldd}{{\mathbf d}}
\newcommand{\bolde}{{\mathbf e}}
\newcommand{\boldi}{{\mathbf i}}
\newcommand{\boldj}{{\mathbf j}}
\newcommand{\boldk}{{\mathbf k}}
\newcommand{\boldn}{{\mathbf n}}
\newcommand{\boldp}{{\mathbf p}}
\newcommand{\boldq}{{\mathbf q}}
\newcommand{\boldr}{{\mathbf r}}
\newcommand{\boldsymbol}{{\mathbf s}}
\newcommand{\boldt}{{\mathbf t}}
\newcommand{\boldu}{{\mathbf u}}
\newcommand{\boldv}{{\mathbf v}}
\newcommand{\boldw}{{\mathbf w}}
\newcommand{\boldx}{{\mathbf x}}
\newcommand{\boldy}{{\mathbf y}}
\newcommand{\boldz}{{\mathbf z}}
\newcommand{\boldzero}{{\mathbf 0}}
\newcommand{\boldmod}{\boldsymbol{ \bmod }}
\newcommand{\boldT}{{\mathbf T}}
\newcommand{\boldN}{{\mathbf N}}
\newcommand{\boldB}{{\mathbf B}}
\newcommand{\boldF}{{\mathbf F}}
\newcommand{\boldS}{{\mathbf S}}
\newcommand{\boldG}{{\mathbf G}}
\newcommand{\boldK}{{\mathbf K}}
\newcommand{\boldL}{{\mathbf L}}
\DeclareMathOperator{\lcm}{lcm}
\DeclareMathOperator{\Span}{span}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\NS}{null}
\DeclareMathOperator{\RS}{row}
\DeclareMathOperator{\CS}{col}
\DeclareMathOperator{\im}{im}
\DeclareMathOperator{\range}{range}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\nullity}{nullity}
\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\Fix}{Fix}
\DeclareMathOperator{\Aff}{Aff}
\DeclareMathOperator{\Frac}{Frac}
\DeclareMathOperator{\Ann}{Ann}
\DeclareMathOperator{\Tor}{Tor}
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\mdeg}{mdeg}
\DeclareMathOperator{\Lt}{Lt}
\DeclareMathOperator{\Lc}{Lc}
\DeclareMathOperator{\disc}{disc}
\DeclareMathOperator{\Frob}{Frob}
\DeclareMathOperator{\adj}{adj}
\DeclareMathOperator{\curl}{curl}
\DeclareMathOperator{\grad}{grad}
\DeclareMathOperator{\diver}{div}
\DeclareMathOperator{\flux}{flux}
\def\Gal{\operatorname{Gal}}
\def\ord{\operatorname{ord}}
\def\ML{\operatorname{M}}
\def\GL{\operatorname{GL}}
\def\PGL{\operatorname{PGL}}
\def\SL{\operatorname{SL}}
\def\PSL{\operatorname{PSL}}
\def\GSp{\operatorname{GSp}}
\def\PGSp{\operatorname{PGSp}}
\def\Sp{\operatorname{Sp}}
\def\PSp{\operatorname{PSp}}
\def\Aut{\operatorname{Aut}}
\def\Inn{\operatorname{Inn}}
\def\Hom{\operatorname{Hom}}
\def\End{\operatorname{End}}
\def\ch{\operatorname{char}}
\def\Zp{\Z/p\Z}
\def\Zm{\Z/m\Z}
\def\Zn{\Z/n\Z}
\def\Fp{\F_p}
\newcommand{\surjects}{\twoheadrightarrow}
\newcommand{\injects}{\hookrightarrow}
\newcommand{\bijects}{\leftrightarrow}
\newcommand{\isomto}{\overset{\sim}{\rightarrow}}
\newcommand{\floor}[1]{\lfloor#1\rfloor}
\newcommand{\ceiling}[1]{\left\lceil#1\right\rceil}
\newcommand{\mclass}[2][m]{[#2]_{#1}}
\newcommand{\val}[2][]{\left\lvert #2\right\rvert_{#1}}
\newcommand{\valuation}[2][]{\left\lvert #2\right\rvert_{#1}}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\anpoly}{a_nx^n+a_{n-1}x^{n-1}\cdots +a_1x+a_0}
\newcommand{\anmonic}{x^n+a_{n-1}x^{n-1}\cdots +a_1x+a_0}
\newcommand{\bmpoly}{b_mx^m+b_{m-1}x^{m-1}\cdots +b_1x+b_0}
\newcommand{\pder}[2]{\frac{\partial#1}{\partial#2}}
\renewcommand{\c}{\cancel}
\newcommand{\normalin}{\trianglelefteq}
\newcommand{\angvec}[1]{\langle #1\rangle}
\newcommand{\varpoly}[2]{#1_{#2}x^{#2}+#1_{#2-1}x^{#2-1}\cdots +#1_1x+#1_0}
\newcommand{\varpower}[1][a]{#1_0+#1_1x+#1_1x^2+\cdots}
\newcommand{\limasto}[2][x]{\lim_{#1\rightarrow #2}}
\def\ntoinfty{\lim_{n\rightarrow\infty}}
\def\xtoinfty{\lim_{x\rightarrow\infty}}
\def\ii{\item}
\def\bb{\begin{enumerate}}
\def\ee{\end{enumerate}}
\def\ds{\displaystyle}
\def\p{\partial}
\newcommand{\abcdmatrix}[4]{\begin{bmatrix}#1\amp #2\\ #3\amp #4 \end{bmatrix}
}
\newenvironment{amatrix}[1][ccc|c]{\left[\begin{array}{#1}}{\end{array}\right]}
\newenvironment{linsys}[2][m]{
\begin{array}[#1]{@{}*{#2}{rc}r@{}}
}{
\end{array}}
\newcommand{\eqsys}{\begin{array}{rcrcrcr}
a_{11}x_{1}\amp +\amp a_{12}x_{2}\amp +\cdots+\amp  a_{1n}x_{n}\amp =\amp b_1\\
a_{21}x_{1}\amp +\amp a_{22}x_{2}\amp +\cdots+\amp a_{2n}x_{n}\amp =\amp b_2\\
\amp \vdots\amp   \amp \vdots \amp  \amp \vdots \amp  \vdots\\
a_{m1}x_{1}\amp +\amp a_{m2}x_{2}\amp +\cdots +\amp a_{mn}x_{n}\amp =\amp b_m
\end{array}
}
\newcommand{\numeqsys}{\begin{array}{rrcrcrcr}
e_1:\amp  a_{11}x_{1}\amp +\amp a_{12}x_{2}\amp +\cdots+\amp  a_{1n}x_{n}\amp =\amp b_1\\
e_2: \amp a_{21}x_{1}\amp +\amp a_{22}x_{2}\amp +\cdots+\amp a_{2n}x_{n}\amp =\amp b_2\\
\amp \vdots\amp   \amp \vdots \amp  \amp \vdots \amp  \vdots\\
e_m: \amp a_{m1}x_{1}\amp +\amp a_{m2}x_{2}\amp +\cdots +\amp a_{mn}x_{n}\amp =\amp b_m
\end{array}
}
\newcommand{\homsys}{\begin{array}{rcrcrcr}
a_{11}x_{1}\amp +\amp a_{12}x_{2}\amp +\cdots+\amp  a_{1n}x_{n}\amp =\amp 0\\
a_{21}x_{1}\amp +\amp a_{22}x_{2}\amp +\cdots+\amp a_{2n}x_{n}\amp =\amp 0\\
\amp \vdots\amp   \amp \vdots \amp  \amp \vdots \amp  \vdots\\
a_{m1}x_{1}\amp +\amp a_{m2}x_{2}\amp +\cdots +\amp a_{mn}x_{n}\amp =\amp 0
\end{array}
}
\newcommand{\vareqsys}[4]{
\begin{array}{ccccccc}
#3_{11}x_{1}\amp +\amp #3_{12}x_{2}\amp +\cdots+\amp  #3_{1#2}x_{#2}\amp =\amp #4_1\\
#3_{21}x_{1}\amp +\amp #3_{22}x_{2}\amp +\cdots+\amp #3_{2#2}x_{#2}\amp =\amp #4_2\\
\vdots \amp \amp \vdots \amp  \amp \vdots \amp =\amp  \vdots\\
#3_{#1 1}x_{1}\amp +\amp #3_{#1 2}x_{2}\amp +\cdots +\amp #3_{#1 #2}x_{#2}\amp =\amp #4_{#1}
\end{array}
}
\newcommand{\genmatrix}[1][a]{
\begin{bmatrix}
#1_{11} \amp  #1_{12} \amp  \cdots \amp  #1_{1n} \\
#1_{21} \amp  #1_{22} \amp  \cdots \amp  #1_{2n} \\
\vdots  \amp  \vdots  \amp  \ddots \amp  \vdots  \\
#1_{m1} \amp  #1_{m2} \amp  \cdots \amp  #1_{mn}
\end{bmatrix}
}
\newcommand{\varmatrix}[3]{
\begin{bmatrix}
#3_{11} \amp  #3_{12} \amp  \cdots \amp  #3_{1#2} \\
#3_{21} \amp  #3_{22} \amp  \cdots \amp  #3_{2#2} \\
\vdots  \amp  \vdots  \amp  \ddots \amp  \vdots  \\
#3_{#1 1} \amp  #3_{#1 2} \amp  \cdots \amp  #3_{#1 #2}
\end{bmatrix}
}
\newcommand{\augmatrix}{
\begin{amatrix}[cccc|c]
a_{11} \amp  a_{12} \amp  \cdots \amp  a_{1n} \amp b_{1}\\
a_{21} \amp  a_{22} \amp  \cdots \amp  a_{2n} \amp b_{2}\\
\vdots  \amp  \vdots  \amp  \ddots \amp  \vdots  \amp \vdots\\
a_{m1} \amp  a_{m2} \amp  \cdots \amp  a_{mn}\amp b_{m}
\end{amatrix}
}
\newcommand{\varaugmatrix}[4]{
\begin{amatrix}[cccc|c]
#3_{11} \amp  #3_{12} \amp  \cdots \amp  #3_{1#2} \amp #4_{1}\\
#3_{21} \amp  #3_{22} \amp  \cdots \amp  #3_{2#2} \amp #4_{2}\\
\vdots  \amp  \vdots  \amp  \ddots \amp  \vdots  \amp \vdots\\
#3_{#1 1} \amp  #3_{#1 2} \amp  \cdots \amp  #3_{#1 #2}\amp #4_{#1}
\end{amatrix}
}
\newcommand{\spaceforemptycolumn}{\makebox[\wd\boxofmathplus]{\ }}
\newcommand{\grstep}[2][\relax]{
\mathrel{
\hspace{\grsteplength}\mathop{\longrightarrow}\limits^{#2\mathstrut}_{
\begin{subarray}{l} #1 \end{subarray}}\hspace{\grsteplength}}}
\newcommand{\repeatedgrstep}[2][\relax]{\hspace{-\grsteplength}\grstep[#1]{#2}}
\newcommand{\swap}{\leftrightarrow}
\newcommand{\deter}[1]{ \mathchoice{\left|#1\right|}{|#1|}{|#1|}{|#1|} }
\newcommand{\generalmatrix}[3]{
\left(
\begin{array}{cccc}
#1_{1,1}  \amp #1_{1,2}  \amp \ldots  \amp #1_{1,#2}  \\
#1_{2,1}  \amp #1_{2,2}  \amp \ldots  \amp #1_{2,#2}  \\
\amp \vdots                         \\
#1_{#3,1} \amp #1_{#3,2} \amp \ldots  \amp #1_{#3,#2}
\end{array}
\right)  }
\newcommand{\colvec}[2][c]{\begin{bmatrix}[#1] #2 \end{bmatrix}}
\newcommand{\rowvec}[1]{\setlength{\arraycolsep}{3pt}\begin{bmatrix} #1 \end{bmatrix}}
\DeclareMathOperator{\trace}{tr}
\newcommand{\isomorphicto}{\cong}
\newcommand{\rangespace}[1]{ \mathscr{R}(#1) }
\newcommand{\nullspace}[1]{ \mathscr{N}(#1) }
\newcommand{\genrangespace}[1]{ \mathscr{R}_\infty(#1) }
\newcommand{\gennullspace}[1]{ \mathscr{N}_\infty(#1) }
\newcommand{\zero}{ \vec{0} }
\newcommand{\polyspace}{\mathcal{P}}
\newcommand{\matspace}{\mathcal{M}}
\DeclareMathOperator{\size}{size}
\DeclareMathOperator{\adjoint}{adj}
\DeclareMathOperator{\sgn}{sgn}
\newcommand{\definend}[1]{\emph{#1}}
\renewcommand{\Re}{\mathbb{R}}
\newcommand{\map}[3]{\mbox{$#1\colon #2\to #3$}}
\newcommand{\mapsunder}[1]{\stackrel{#1}{\longmapsto}}
\newcommand{\mapsvia}[1]{\xrightarrow{#1}}
\newcommand{\xmapsunder}[1]{\mapsunder{#1}}
\newcommand{\composed}[2]{#1\mathbin{\circ} #2}
\DeclareMathOperator{\identity}{id}
\newcommand{\restrictionmap}[2]{{#1}\mathpunct\upharpoonright\hbox{}_{#2}}
\renewcommand{\emptyset}{\varnothing}
\newcommand{\setspacing}{0.1em}
\newcommand{\set}[1]{\mbox{$\{\hspace{\setspacing}#1\hspace{\setspacing}\}$}}
\newcommand{\suchthat}{\mid}
\newcommand{\union}{\cup}
\newcommand{\intersection}{\cap}
\newcommand{\sequence}[1]{ \langle#1\rangle }
\newcommand{\interval}[2]{#1\,\ldots\, #2}
\newcommand{\setinterval}[2]{\mbox{$\{\interval{#1}{#2}\}$}}
\newcommand{\openinterval}[2]{(\interval{#1}{#2})}
\newcommand{\closedinterval}[2]{[\interval{#1}{#2}]}
\newcommand{\clopinterval}[2]{[\interval{#1}{#2})}
\newcommand{\opclinterval}[2]{(\interval{#1}{#2}]}
\newcommand{\isimpliedby}{\Longleftarrow}
\newcommand{\Sage}{\textit{Sage}}
\newcommand{\Maple}{\textit{Maple}}
\newcommand{\cat}[2]{#1\!\mathbin{\raise.6ex\hbox{\left( {}^\frown \right)}}\!#2}
\newcommand{\alignedvdots}[1][10pt]{\mskip2.5mu\makebox[.5\equalsignwd][r]{}
\smash{\vdots}}
\newcommand{\stdbasis}{{\cal E}}
\newcommand{\basis}[2]{\sequence{\vec{#1}_1,\ldots,\vec{#1}_{#2}}}
\newcommand{\rowspace}[1]{ \mathop{{\mbox{Rowspace}}}(#1) }
\newcommand{\colspace}[1]{ \mathop{{\mbox{Columnspace}}}(#1) }
\newcommand{\linmaps}[2]{ \mathop{{\cal L}}(#1,#2) }
\newcommand{\lincombo}[2]{
#1_1#2_1+#1_2#2_2+\cdots +#1_n#2_n}
\newcommand{\rep}[2]{ { Rep}_{#2}(#1) }
\newcommand{\wrt}[1]{{\mbox{\scriptsize \textit{wrt}\hspace{.25em}\left( #1 \right)} }}
\newcommand{\trans}[1]{ {{#1}^{\mathsf{T}}} }
\newcommand{\proj}[2]{\mbox{proj}_{#2}({#1}) }
\newcommand{\spanof}[1]{\relax [#1\relax ]}
\newcommand{\directsum}{\oplus}
\DeclareMathOperator{\dist}{dist}
\newcommand{\nbyn}[1]{#1 \! \times \! #1 }
\newcommand{\nbym}[2]{#1 \! \times \! #2 }
\newcommand{\degs}[1]{#1^\circ\relax}
\newcommand{\votepreflist}[3]{\colvec{#1 \\ #2 \\ #3}}
\newcommand{\votinggraphic}[1]{\hspace{1.15em}\mathord{[.3in][.2in]{\includegraphics{voting.#1}}}\hspace{1.15em}}
\newcommand{\magicsquares}{\mathscr{M}}
\newcommand{\semimagicsquares}{\mathscr{H}}
\newcommand{\circuitfont}{\sffamily}
\newcommand{\digitinsq}[1]{\fbox{\left( #1 \right)} }
\newcommand{\matrixvenlarge}[1]{\vbox{
\vspace{\extramatrixvspace}
\hbox{$#1$}
\vspace{\extramatrixvspace}
}}
\def\bspace{
{\vspace{.05in}}}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\)</div>
<header id="masthead" class="smallbuttons"><div class="banner"><div class="container">
<a id="logo-link" href=""></a><div class="title-container">
<h1 class="heading"><a href="book-1.html"><span class="title">Linear algebra: the theory of vector spaces</span></a></h1>
<p class="byline">Aaron Greicius</p>
</div>
</div></div>
<nav xmlns:svg="http://www.w3.org/2000/svg" id="primary-navbar" class="navbar"><div class="container">
<div class="navbar-top-buttons">
<button class="sidebar-left-toggle-button button active" aria-label="Show or hide table of contents sidebar">Contents</button><div class="tree-nav toolbar toolbar-divisor-3">
<a class="index-button toolbar-item button" href="index-1.html" title="Index">Index</a><span class="threebuttons"><a id="previousbutton" class="previous-button toolbar-item button" href="c_innerproductspaces.html" title="Previous">Prev</a><a id="upbutton" class="up-button button toolbar-item" href="c_innerproductspaces.html" title="Up">Up</a><a id="nextbutton" class="next-button button toolbar-item" href="ss_orthogonality.html" title="Next">Next</a></span>
</div>
</div>
<div class="navbar-bottom-buttons toolbar toolbar-divisor-4">
<button class="sidebar-left-toggle-button button toolbar-item active">Contents</button><a class="previous-button toolbar-item button" href="c_innerproductspaces.html" title="Previous">Prev</a><a class="up-button button toolbar-item" href="c_innerproductspaces.html" title="Up">Up</a><a class="next-button button toolbar-item" href="ss_orthogonality.html" title="Next">Next</a>
</div>
</div></nav></header><div class="page">
<div xmlns:svg="http://www.w3.org/2000/svg" id="sidebar-left" class="sidebar" role="navigation"><div class="sidebar-content">
<nav id="toc"><ul>
<li class="link frontmatter"><a href="frontmatter-1.html" data-scroll="frontmatter-1"><span class="title">Front Matter</span></a></li>
<li class="link">
<a href="c_linear_systems.html" data-scroll="c_linear_systems"><span class="codenumber">1</span> <span class="title">Linear systems of equations</span></a><ul>
<li><a href="s_systems.html" data-scroll="s_systems">Linear systems of equations</a></li>
<li><a href="s_ge.html" data-scroll="s_ge">Gaussian elimination</a></li>
<li><a href="s_solving.html" data-scroll="s_solving">Solving linear systems</a></li>
<li><a href="ss_matrix.html" data-scroll="ss_matrix">Matrix arithmetic</a></li>
<li><a href="ss_algebraic.html" data-scroll="ss_algebraic">Algebraic properties</a></li>
<li><a href="ss_elementary.html" data-scroll="ss_elementary">Elementary matrices</a></li>
<li><a href="ss_invertible.html" data-scroll="ss_invertible">More on invertibility</a></li>
</ul>
</li>
<li class="link">
<a href="c_det.html" data-scroll="c_det"><span class="codenumber">2</span> <span class="title">The determinant</span></a><ul>
<li><a href="ss_det.html" data-scroll="ss_det">The determinant</a></li>
<li><a href="ss_rowops.html" data-scroll="ss_rowops">Row operations and the determinant</a></li>
<li><a href="ss_further.html" data-scroll="ss_further">Further properties</a></li>
</ul>
</li>
<li class="link">
<a href="c_vectorspace.html" data-scroll="c_vectorspace"><span class="codenumber">3</span> <span class="title">Vector spaces and linear transformations</span></a><ul>
<li><a href="ss_vectorspace.html" data-scroll="ss_vectorspace">Real vector spaces</a></li>
<li><a href="ss_transformation.html" data-scroll="ss_transformation">Linear transformations</a></li>
<li><a href="ss_subspace.html" data-scroll="ss_subspace">Subspaces</a></li>
<li><a href="ss_independence.html" data-scroll="ss_independence">Linear independence</a></li>
<li><a href="ss_basis.html" data-scroll="ss_basis">Bases</a></li>
<li><a href="ss_dimension.html" data-scroll="ss_dimension">Dimension</a></li>
</ul>
</li>
<li class="link">
<a href="c_transbasis.html" data-scroll="c_transbasis"><span class="codenumber">4</span> <span class="title">Linear transformations, bases, and dimension</span></a><ul>
<li><a href="ss_rank-nullity.html" data-scroll="ss_rank-nullity">Linear transformations and bases</a></li>
<li><a href="ss_rank-nullity.html" data-scroll="ss_rank-nullity">Linear transformations and bases</a></li>
<li><a href="ss_coordinate.html" data-scroll="ss_coordinate">Coordinate vectors</a></li>
<li><a href="ss_matrixreps.html" data-scroll="ss_matrixreps">Matrix representations</a></li>
<li><a href="ss_changeofbasis.html" data-scroll="ss_changeofbasis">Change of basis</a></li>
<li><a href="ss_eigenvectors.html" data-scroll="ss_eigenvectors">Eigenvectors and eigenvalues</a></li>
<li><a href="ss_diagonalization.html" data-scroll="ss_diagonalization">Diagonalization</a></li>
</ul>
</li>
<li class="link">
<a href="c_innerproductspaces.html" data-scroll="c_innerproductspaces"><span class="codenumber">5</span> <span class="title">Inner product spaces</span></a><ul>
<li><a href="ss_innerproducts.html" data-scroll="ss_innerproducts" class="active">Inner products, norms, angles</a></li>
<li><a href="ss_orthogonality.html" data-scroll="ss_orthogonality">Orthogonality, Gram-Schmidt, orthogonal projection</a></li>
</ul>
</li>
<li class="link backmatter"><a href="backmatter-1.html" data-scroll="backmatter-1"><span class="title">Back Matter</span></a></li>
<li class="link"><a href="appendix-defs.html" data-scroll="appendix-defs"><span class="codenumber">A</span> <span class="title">Definitions</span></a></li>
<li class="link"><a href="appendix-thms.html" data-scroll="appendix-thms"><span class="codenumber">B</span> <span class="title">Theorems</span></a></li>
<li class="link"><a href="appendix-egs.html" data-scroll="appendix-egs"><span class="codenumber">C</span> <span class="title">Examples</span></a></li>
<li class="link"><a href="references-1.html" data-scroll="references-1"><span class="title">Bibliography</span></a></li>
<li class="link"><a href="index-1.html" data-scroll="index-1"><span class="title">Index</span></a></li>
</ul></nav><div class="extras"><nav><a class="mathbook-link" href="https://pretextbook.org">Authored in PreTeXt</a><a href="https://www.mathjax.org"><img title="Powered by MathJax" src="https://www.mathjax.org/badge/badge.gif" alt="Powered by MathJax"></a></nav></div>
</div></div>
<main class="main"><div id="content" class="pretext-content"><section xmlns:svg="http://www.w3.org/2000/svg" class="section" id="ss_innerproducts"><h2 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber">5.1</span> <span class="title">Inner products, norms, angles</span>
</h2>
<article class="paragraphs" id="paragraphs-242"><h5 class="heading"><span class="title">Inner product spaces.</span></h5>
<p id="p-1187">We now define the notion of an inner product \(\langle v,w \rangle\) on a vector space \(V\text{.}\)</p>
<p id="p-1188">An inner product is an additional layer of structure added to the vector space operations defined on \(V\text{.}\) As with those operations, we define inner products <em class="emphasis">axiomatically</em>.</p>
<p id="p-1189">The dot product operation defined on \(\R^2\) and \(\R^3\) serves as the basic model of an inner product; our axioms simply generalize prominent and useful properties of this particular inner product.</p>
<p id="p-1190">The main virtues of an inner product are:</p>
<ol class="decimal">
<li id="li-295"><p id="p-1191">it allows us to define notions of orthogonality, distance and angle on \(V\text{;}\)</p></li>
<li id="li-296"><p id="p-1192">it allows us to construct <em class="emphasis">orthonormal</em> bases of \(V\text{,}\) which are computationally very easy to work with.</p></li>
</ol></article><article class="paragraphs" id="paragraphs-243"><h5 class="heading"><span class="title">Definition of inner product.</span></h5>
<article class="definition definition-like" id="definition-50"><h6 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">5.1.1</span><span class="period">.</span>
</h6>
<p id="p-1193">Let \(V\) be a vector space. An <dfn class="terminology">inner product</dfn> on \(V\) is an operation</p>
<div class="displaymath">
\begin{align*}
\langle \ , \rangle \colon \amp V\times V\rightarrow \R\\
(\boldv_1,\boldv_2)\amp \mapsto \langle \boldv_1,\boldv_2\rangle
\end{align*}
</div>
<p class="continuation">satisfying the following axions:</p>
<div class="displaymath">
\begin{align*}
\langle \boldv,\boldw\rangle\amp =\langle \boldw,\boldv\rangle \amp \text{ (Symmetry) }\\
\langle c\boldu+d\boldv,\boldw\rangle\amp =c\langle\boldu,\boldw\rangle+d\langle\boldv,\boldw\rangle \amp \text{ (Linearity in first variable) }\\
\langle \boldv,\boldv\rangle\geq 0\text{ and } \langle \boldv,\boldv\rangle \amp =0 \text{ iff  } \boldv=\boldzero \amp \text{ (Positivity) }
\end{align*}
</div>
<p id="p-1194">A vector space \(V\) along with a choice of inner product \(\langle \ , \rangle\) is called an <dfn class="terminology">inner product space</dfn>.</p></article></article><article class="paragraphs" id="paragraphs-244"><h5 class="heading"><span class="title">Example: the dot product on $\R^n$.</span></h5>
<article class="definition definition-like" id="definition-51"><h6 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">5.1.2</span><span class="period">.</span>
</h6>
<p id="p-1195">Given \(\boldv=(v_1,\dots,v_n), \boldw=(w_1,\dots,w_n)\in\R^n\text{,}\) we define the <dfn class="terminology">dot product</dfn> as</p>
<div class="displaymath">
\begin{equation*}
\boldv\cdot\boldw=v_1w_1+v_2w_2+\cdots +v_nw_n\text{.}
\end{equation*}
</div></article><p id="p-1196">It is easy to see that the dot product satisfies the axioms of an inner product on \(\R^n\)</p>
<p id="p-1197">In fact, if we identify \(n\)-tuples with column vectors (or row vectors), then we can express the dot product as a certain matrix multiplication, in which case the inner product axioms follow simply from properties of matrix multiplication!</p>
<article class="paragraphs" id="paragraphs-245"><h5 class="heading"><span class="title">Columns:.</span></h5>
<p id="p-1198">think of \(\boldv\) and \(\boldw\) as \(n\times 1\) column vectors. Then</p></article><div class="displaymath">
\begin{equation*}
\boldv\cdot\boldw=\boldv^T\boldw\text{.}
\end{equation*}
</div>
<article class="paragraphs" id="paragraphs-246"><h5 class="heading"><span class="title">Rows:.</span></h5>
<p id="p-1199">think of \(\boldv\) and \(\boldw\) as \(1\times n\) row vectors. Then</p></article><div class="displaymath">
\begin{equation*}
\boldv\cdot\boldw=\boldv\boldw^T
\end{equation*}
</div></article><article class="paragraphs" id="paragraphs-247"><h5 class="heading"><span class="title">Dot product method of matrix multiplication.</span></h5>
<p id="p-1200">The last observations also give us yet another way of looking at matrix multiplication! Take \(A=[a_{ij}]_{m\times n}\) and \(B=[b_{ij}]_{n\times r}\text{.}\) Think of \(A=\begin{bmatrix}-\bolda_1-\\ \vdots \\ -\bolda_m- \end{bmatrix}\) as a collection of \(m\) {row} vectors in \(\R^n\text{,}\) and \(B=\begin{bmatrix}\vert \amp \amp \vert\\ \boldb_1\amp \cdots \amp \boldb_r\\ \vert \amp \amp \vert \end{bmatrix}\) as a collection of \(r\) {column} vectors in \(\R^n\text{.}\)</p>
<p id="p-1201">Set \(AB=C=[c_{ij}]_{m\times r}\text{.}\) It follows directly from the original definition of matrix multiplication that</p>
<div class="displaymath">
\begin{equation*}
c_{ij}=\bolda_i\cdot\boldb_j\text{.}
\end{equation*}
</div>
<p id="p-1202">That is, the \(ij\)-th entry of \(AB\) is simply the dot product of the \(i\)-th row of \(A\) and the \(j\)-th column of \(B\text{!}\)</p></article><article class="paragraphs" id="paragraphs-248"><h5 class="heading"><span class="title">Inner products on $\R^n$.</span></h5>
<p id="p-1203">Let \(\boldx=(x_1,x_2,\dots ,x_n)\) and \(y=(y_1,y_2,\dots y_n)\) throughout. We consider \(\boldx\) and \(\boldy\) as columns by default.</p>
<article class="paragraphs" id="paragraphs-249"><h5 class="heading"><span class="title">Example 1.</span></h5>
<p id="p-1204">The <em class="emphasis">dot product</em> \(\langle\boldx,\boldy\rangle:=x_1y_1+x_2y_2+\cdots x_ny_n\) is an inner product on \(\R^n\text{.}\)</p></article><article class="paragraphs" id="paragraphs-250"><h5 class="heading"><span class="title">Example 2.</span></h5>
<p id="p-1205">For any choice of <em class="emphasis">positive constants</em> \(c_1,c_2,\dots c_n&gt;0\text{,}\) the <em class="emphasis">weighted dot product</em> \(\langle \boldx,\boldy\rangle:=c_1x_1y_1+c_2x_2y_2+\cdots +c_nx_ny_n\) is an inner product on \(\R^n\text{.}\)</p></article><article class="paragraphs" id="paragraphs-251"><h5 class="heading"><span class="title">Example 3.</span></h5>
<p id="p-1206">(Why we need \(c_i&gt;0\)). The operation \(\langle\boldx,\boldy\rangle=2x_1y_1+(-1)x_2y_2\) is NOT an inner product on \(\R^2\) as \(\langle (1,\sqrt{2}), (1,\sqrt{2})\rangle=2-2=0\text{,}\) in violation of positivity.</p></article><article class="paragraphs" id="paragraphs-252"><h5 class="heading"><span class="title">Example 4.</span></h5>
<p id="p-1207">Looking forward a bit, it turns out that Examples 1 and 2 are cases of the following more general construction.</p></article><p id="p-1208">Let \(A\) be any symmetric \(n\times n\) matrix, all of whose eigenvalues are <em class="emphasis">positive</em>. Then the operation</p>
<div class="displaymath">
\begin{equation*}
\langle \boldx, \boldy\rangle:=\boldx^TA\boldy
\end{equation*}
</div>
<p class="continuation">defines an inner product on \(\R^n\text{.}\)</p>
<p id="p-1209">Example 1 is the case where \(A=I\text{.}\)</p>
<p id="p-1210">Example 2 is the case where \(A=\begin{bmatrix}c_1\amp 0\amp 0\amp \dots\\ 0\amp c_2\amp 0\amp \dots \\ \vdots \amp \\ 0\amp 0\amp \dots\amp c_n \end{bmatrix}\)</p></article><article class="paragraphs" id="paragraphs-253"><h5 class="heading"><span class="title">Inner products on $P_n$.</span></h5>
<p id="p-1211">Throughout we let \(p(x)=a_nx^n+\cdots +a_1x+a_0\) and \(q(x)=b_nx^n+\cdots +b_1x+b_0\text{.}\)</p>
<article class="paragraphs" id="paragraphs-254"><h5 class="heading"><span class="title">Example 1.</span></h5>
<p id="p-1212">The operation \(\langle p(x),q(x)\rangle :=a_0b_0+a_1b_1+\cdots +a_nb_n\) defines an inner product on \(P_n\text{.}\) (This is just the dot product in disguise!)</p></article><article class="paragraphs" id="paragraphs-255"><h5 class="heading"><span class="title">Example 2.</span></h5>
<p id="p-1213">Fix any distinct constants \(c_0,c_1,\dots ,c_n\text{.}\) Then the operation \(\langle p(x),
q(x)\rangle=p(c_0)q(c_0)+p(c_1)q(c_1)+\cdots +p(c_n)q(c_n)\) defines an inner product, called an <em class="emphasis">evaluation inner product</em>.</p></article><article class="hiddenproof" id="proof-54"><a data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-54"><h6 class="heading"><span class="type">Proof<span class="period">.</span></span></h6></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-54"><article class="hiddenproof"><p id="p-1214">It is fairly clear that the evaluation product is symmetric and linear in each variable.</p>
<p id="p-1215">Consider positivity. We have \(\langle p(x),
p(x)\rangle:=p(c_0)^2+p(c_1)^2+\cdots +p(c_n)^2\geq 0\text{,}\) since each term is a square.</p>
<p id="p-1216">Furthermore we see this sum is equal to 0 iff \(p(c_i)=0\) for all \(i\text{.}\) But this is the case iff \(p(x)=\boldzero\) is the zero polynomial, as no other polynomial in \(P_n\) can have \(n+1\) distinct roots!</p></article></div></article><article class="paragraphs" id="paragraphs-256"><h5 class="heading"><span class="title">Standard inner product on $M_{mn}$.</span></h5>
<p id="p-1217">Given \(A, B\in M_{mn}\text{,}\) we define \(\langle A, B\rangle=\tr (A^TB)\text{.}\) Recall: the trace \(\tr(C)\) of a matrix is the sum of its diagonal entries.</p>
<p id="p-1218">It is an interesting exercise to show the operation thus defined does indeed satisfy three axioms.</p>
<p id="p-1219">(i) The fact that \(\langle A,B\rangle=\langle B,A \rangle\) follows from the fact that \(\tr(A^TB)=\tr(B^TA)\text{.}\) Can you prove the latter? Hint: what is the relation between \(A^TB\) and \(B^TA\text{?}\)</p>
<p id="p-1220">(ii) Bilinearity follows easily from <em class="emphasis">three</em> different distributive properties: (a) for matrix multiplication, (b) for taking transposes, and (c) for taking the trace.</p>
<p id="p-1221">(iii) Positivity is the most challenging. The most direct way of proving that this property holds is to let \(A=[a_{ij}]\) and actually compute a formula for \(\tr(A^TA)\) in terms of the \(a_{ij}\text{.}\) I leave it to you.</p></article><article class="paragraphs" id="paragraphs-257"><h5 class="heading"><span class="title">Standard inner product on function spaces.</span></h5>
<p id="p-1222">Let \(V=C([a,b])\) where \([a,b]\) is some fixed interval.</p>
<p id="p-1223">The <em class="emphasis">standard inner product</em> on \(C([a,b])\) is defined via an integral:</p>
<div class="displaymath">
\begin{equation*}
\langle f(x), g(x)\rangle:=\int_a^b f(x)g(x) \, dx\text{.}
\end{equation*}
</div>
<p id="p-1224">(Note that continuity of \(f\) and \(g\) ensures this integral exists and is finite!)</p>
<article class="hiddenproof" id="proof-55"><a data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-55"><h6 class="heading"><span class="type">Proof<span class="period">.</span></span></h6></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-55"><article class="hiddenproof"><p id="p-1225"><dfn class="terminology">Symmetry</dfn>: \(\langle f,g\rangle=\int_a^b fg\, dx=\int_a^b gf\, dx=\langle g,f\rangle\)</p>
<p id="p-1226"><dfn class="terminology">Linearity</dfn>: \(\langle cf+dg,h\rangle=\int_a^b(cf(x)+dg(x))h(x)\, dx=c\int_a^bf(x)h(x)\, dx+d\int_a^bg(x)h(x)\, dx=c\langle f,h\rangle + d\langle g,h \rangle\)</p>
<p id="p-1227"><dfn class="terminology">Positivity</dfn>: we have \(\langle f, f\rangle=\int_a^b f^2(x)\, dx\text{.}\)</p>
<p id="p-1228">We have \(f^2(x)\geq 0\) for all \(x\text{;}\) i.e., \(f^2\) is nonnegative. It follows from some basic calculus that the integral of \(f^2\) is always nonnegative. Furthermore, since \(f^2\) is also <em class="emphasis">continuous</em> the integral is 0 iff \(f^2=0\) iff \(f=0\text{.}\) This proves positivity.</p></article></div></article><article class="paragraphs" id="paragraphs-258"><h5 class="heading"><span class="title">Further properties of inner products.</span></h5>
<p id="p-1229">The following properties follow formally from the defining axioms of an inner product space.</p>
<div class="displaymath">
\begin{align*}
\langle\boldu,c\boldv+d\boldw\rangle\amp =c\langle\boldu,\boldv\rangle+d\langle\boldu,\boldw\rangle \amp \text{ (Linearity in second variable) }\\
\langle\boldzero,\boldv\rangle\amp =\langle\boldv,\boldzero\rangle=0
\end{align*}
</div>
<p id="p-1230">The first property follows easily from linearity in the first variable and symmetry.</p>
<p id="p-1231">Note: the fact that the inner product is linear in both variables is an important property that we call <em class="emphasis">bilinearity</em>.</p>
<p id="p-1232">To prove the second property it is enough by symmetry to prove \(\langle\boldzero,\boldv\rangle=0\text{.}\) (Note the two different types of zero here!)</p>
<p id="p-1233">We have</p>
<div class="displaymath">
\begin{align*}
\langle\boldzero,\boldv\rangle\amp =\langle 0\cdot\boldzero,\boldv\rangle \amp \text{ (since \(0\cdot\boldzero=\boldzero\)) }\\
\amp =0\langle\boldzero,\boldv\rangle \amp \text{ (linearity in first variable) }\\
\amp =0
\end{align*}
</div></article><article class="paragraphs" id="paragraphs-259"><h5 class="heading"><span class="title">Orthogonality, norm, distance, angle.</span></h5>
<p id="p-1234">Given an inner product space \((V, \langle \ , \rangle)\) we define the following notions.</p>
<article class="paragraphs" id="paragraphs-260"><h5 class="heading"><span class="title">Orthogonality.</span></h5>
<p id="p-1235">: vectors \(\boldv\) and \(\boldw\) are <dfn class="terminology">orthogonal</dfn> if \(\langle \boldv,\boldw\rangle=0\text{.}\)</p></article><article class="paragraphs" id="paragraphs-261"><h5 class="heading"><span class="title">Norm.</span></h5>
<p id="p-1236">: the <dfn class="terminology">norm</dfn> (or <dfn class="terminology">length</dfn>) of a vector \(\boldv\) is defined as</p></article><div class="displaymath">
\begin{equation*}
\norm{\boldv}:=\sqrt{\langle\boldv,\boldv\rangle}\text{.}
\end{equation*}
</div>
<p id="p-1237">A <dfn class="terminology">unit vector</dfn> is a vector \(\boldv\) with \(\norm{\boldv}=1\text{.}\) Given any vector \(\boldv\text{,}\) one can show that \(\boldu=(\frac{1}{\norm{\boldv}})\boldv\) (or \(\frac{\boldv}{\norm{\boldv}}\) by slight abuse of notation) is a unit vector.</p>
<article class="paragraphs" id="paragraphs-262"><h5 class="heading"><span class="title">Distance:.</span></h5>
<p id="p-1238">the <dfn class="terminology">distance</dfn> between two vectors \(\boldv\) and \(\boldw\) is defined as</p></article><div class="displaymath">
\begin{equation*}
d(\boldv,\boldw)=\norm{\boldv-\boldw}\text{.}
\end{equation*}
</div>
<article class="paragraphs" id="paragraphs-263"><h5 class="heading"><span class="title">Angle:.</span></h5>
<p id="p-1239">the <dfn class="terminology">angle</dfn> between two vectors \(\boldv\) and \(\boldw\) is defined as the unique \(0\leq \theta \leq \pi\) satisfying</p></article><div class="displaymath">
\begin{equation*}
\cos(\theta)=\frac{\langle\boldv,\boldw\rangle}{\norm{\boldv}\norm{\boldw}}\text{.}
\end{equation*}
</div>
<p id="p-1240">Of course for this to make sense we better have</p>
<div class="displaymath">
\begin{equation*}
\val{\langle\boldv,\boldw\rangle}\leq\norm{\boldv}\norm{\boldw}
\end{equation*}
</div>
<p id="p-1241">This is the content of the Cauchy-Schwarz inequality!</p></article><article class="paragraphs" id="paragraphs-264"><h5 class="heading"><span class="title">Cauchy-Schwarz Inequality.</span></h5>
<article class="theorem theorem-like" id="theorem-52"><h6 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">5.1.3</span><span class="period">.</span><span class="space"> </span><span class="title">Cauchy-Schwarz inequality.</span>
</h6>
<p id="p-1242">Let \((V,\langle \ , \rangle)\) be an inner product space. Then for all \(\boldv,\boldw\in V\)</p>
<div class="displaymath">
\begin{equation*}
\val{\langle\boldv,\boldw\rangle}\leq\norm{\boldv}\norm{\boldw}\text{.}
\end{equation*}
</div>
<p id="p-1243">Furthermore, we have an actual equality above iff \(\boldv=c\boldw\) for some \(c\in\R\text{.}\)</p></article><article class="hiddenproof" id="proof-56"><a data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-56"><h6 class="heading"><span class="type">Proof<span class="period">.</span></span></h6></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-56"><article class="hiddenproof"><p id="p-1244">Fix any two vectors \(\boldv\) and \(\boldw\text{.}\) For any \(t\in\R\) we have by positivity</p>
<div class="displaymath">
\begin{equation*}
0\leq \langle t\boldv-\boldw,t\boldv-\boldw\rangle=\langle\boldv,\boldv\rangle t^2-2\langle\boldv,\boldw\rangle t+\langle\boldw,\boldw\rangle=at^2-2bt+c=f(t)\text{,}
\end{equation*}
</div>
<p class="continuation">where \(a=\langle\boldv,\boldv\rangle=\norm{v}^2\text{,}\) \(b=\langle\boldv,\boldw\rangle\) and \(c=\langle\boldw,\boldw\rangle=\norm{w}^2\text{.}\)</p>
<p id="p-1245">The inequality \(f(t)\geq 0\) tells us that the quadratic polynomial \(f(t)\) has <em class="emphasis">at most</em> one root. This means its discriminant \(4b^2-4ac\leq 0\text{,}\) since otherwise there would be two roots.</p>
<p id="p-1246">Subbing back in for \(a,b,c\) and rearranging yields</p>
<div class="displaymath">
\begin{equation*}
(\langle\boldv,\boldw\rangle)^2\leq \norm{\boldv}^2\norm{\boldw}^2\text{.}
\end{equation*}
</div>
<p id="p-1247">Taking square-roots yields the desired inequality.</p>
<p id="p-1248">The same reasoning shows that the Cauchy-Schwarz inequality is an actual equality iff \(f(t)=0\) for some \(t\) iff \(0=\langle t\boldv-\boldw,t\boldv-\boldw\rangle\) iff \(\boldv=t\boldw\) for some \(t\) (by positivity).</p></article></div></article><article class="paragraphs" id="paragraphs-265"><h5 class="heading"><span class="title">Triangle Inequalities.</span></h5>
<p id="p-1249">The following so-called triangle inequalities are now just formal consequences of Cauchy-Schwarz.</p>
<article class="theorem theorem-like" id="theorem-53"><h6 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">5.1.4</span><span class="period">.</span><span class="space"> </span><span class="title">Triangle Inequalities.</span>
</h6>
<p id="p-1250">Let \((V, \langle \ , \rangle)\) be any inner product space. Then</p>
<ol class="decimal">
<li id="li-297"><p id="p-1251">\(\displaystyle \norm{\boldv+\boldw}\leq \norm{\boldv}+\norm{\boldw}\)</p></li>
<li id="li-298"><p id="p-1252">\(\displaystyle d(\boldv,\boldw)\leq d(\boldv,\boldu)+d(\boldu,\boldw)\)</p></li>
</ol></article></article><article class="paragraphs" id="paragraphs-266"><h5 class="heading"><span class="title">Choosing your inner product.</span></h5>
<p id="p-1253">Why, given a fixed vector space \(V\text{,}\) would we prefer one inner product definition to another?</p>
<p id="p-1254">One way of understanding a particular choice of inner product is to ask what its corresponding notion of distance measures.</p>
<article class="paragraphs" id="paragraphs-267"><h5 class="heading"><span class="title">Example.</span></h5>
<p id="p-1255">Take \(P_n\) with the evaluation inner product at inputs \(x=c_0, c_1,\dots, c_n\text{.}\) Given two polynomials \(p(x), q(x)\text{,}\) the distance between them with respect to this inner product is</p></article><div class="displaymath">
\begin{equation*}
\norm{p(x)-q(x)}=\sqrt{(p(c_0)-q(c_0))^2+(p(c_1)-q(c_1))^2+\cdots +(p(c_n)-q(c_n))^2}\text{.}
\end{equation*}
</div>
<p id="p-1256">So in this inner product space the “distance” between two polynomials is a measure of how different their values are at the inputs \(x=c_0,c_1,\dots ,c_n\text{.}\) This inner product may be useful if you are particularly interested in how a polynomial behaves at this finite list of inputs.</p>
<article class="paragraphs" id="paragraphs-268"><h5 class="heading"><span class="title">Example.</span></h5>
<p id="p-1257">Take \(C[a,b]\) with the standard inner product \(\langle f, g \rangle=\int_a^b f(x)g(x) \ dx\text{.}\) Here the distance between two functions is defined as \(\ds \norm{f-g}=\sqrt{\int_a^b (f(x)-g(x))^2 \ dx}\text{.}\) In particular, a function \(f\) is “close” to the zero function (i.e. “is small” ) if the <em class="emphasis">integral</em> of \(f^2\) is small. This notion is useful in settings where integrals of functions represent quantities we are interested in (e.g. in probability theory, thermodynamics, wave and quantum mechanics).</p></article></article></section></div></main>
</div>
</body>
</html>
